
"""

To run the full pipeline, submit the following line from within the
same directory as the Snakefile while on the head node (the paths to
the data files are relative to the Snakefile):

nohup snakemake -kp -j 96 --ri -c "qsub -l h_vmem={params.h_vmem} -l bigio={params.bigio} -N {params.name} -V -j y -cwd -o {log}" &

"""

from Bio import SeqIO

###############################################################################
# SOFTWARE
###############################################################################
FASTQC='/mnt/lustre/data/tools/FastQC/'
UMITOOLS='/mnt/lustre/home/jdblischak/programs/virtualenv-1.11/py2.7/bin/'
SAMTOOLS = '/usr/local/bin/'
SUBREAD = '/home/jdblischak/src/subread-1.4.4-Linux-x86_64/bin/'

###############################################################################
# Data
###############################################################################
DATA_DIR = 'data/'
UMI_DIR = DATA_DIR + 'umi/'
POP_DIR = DATA_DIR + 'population/'
LOG_DIR = 'log/'
REF_GENOME = DATA_DIR + 'genome/combined' # prefix only

###############################################################################
# Target rules
###############################################################################

localrules: all, qc

samples = glob_wildcards(UMI_DIR + '{seq}.fastq.gz')

rule all:
	input: DATA_DIR + 'count_matrix.txt'

rule qc:
	input: [UMI_DIR + f.replace('.fastq.gz', '_fastqc.zip') for f in samples.seq]

###############################################################################
# Per-fastq processing: from raw reads to gene counts
###############################################################################

rule unzip:
	input: UMI_DIR + '{seq}.fastq.gz'
	output: temp(UMI_DIR + '{seq}.fastq')
	message: 'Unzipping sample {input}'
	params: h_vmem = '8g', bigio = '0',
	        name = lambda wildcards: 'unzip.' + wildcards.seq
	log: LOG_DIR
	shell: 'zcat {input} > {output}'

rule fastqc:
	input: UMI_DIR + '{seq}.fastq'
	output: UMI_DIR + '{seq}_fastqc.zip'
	message: 'Running FastQC on sample {input}'
	params: h_vmem = '8g', bigio = '0',
	        name = lambda wildcards: 'fastqc.' + wildcards.seq
	log: LOG_DIR
	shell: '{FASTQC}fastqc {input}'

rule trim_umi:
	input: UMI_DIR + '{seq}.fastq'
	output: temp(UMI_DIR + '{seq}.trim.fastq')
	message: 'Trim UMIs from 5\' end of reads of sample {input}'
	params: h_vmem = '8g', bigio = '0',
	        name = lambda wildcards: 'trim_umi.' + wildcards.seq
	log: LOG_DIR
	shell: '{UMITOOLS}umitools trim --end 5 {input} NNNNNGGG --verbose > {output}'

rule map:
	input: fastq = UMI_DIR + '{seq}.trim.fastq',
               genome = REF_GENOME + '.reads'
	output: temp(UMI_DIR + '{seq}.bam')
	message: 'Map reads of sample {input.fastq}'
	params: h_vmem = '12g', bigio = '1',
	        name = lambda wildcards: 'map.' + wildcards.seq
	log: LOG_DIR
	shell: '{SUBREAD}subread-align -i {REF_GENOME} -r {input.fastq} --BAMoutput > {output}'

rule merge_bam:
	input: expand(UMI_DIR + '{seq}.bam', seq = samples.seq)
	output: temp(UMI_DIR + 'two_cell.merged.bam')
	message: 'Merge bam files.'
	params: h_vmem = '16g', bigio = '1',
	        name = 'merge_bam'
	log: LOG_DIR
	shell: '{SAMTOOLS}samtools merge {output} {input}'


rule sort_bam:
	input: UMI_DIR + 'two_cell.merged.bam'
	output: UMI_DIR + 'two_cell.sorted.bam'
	message: 'Sort bam file {input}'
	params: h_vmem = '16g', bigio = '1',
	        name = 'sort_bam',
                prefix = UMI_DIR + 'two_cell.sorted'
	log: LOG_DIR
	shell: '{SAMTOOLS}samtools sort {input} {params.prefix}'

rule index_bam:
	input: UMI_DIR + 'two_cell.sorted.bam'
	output: UMI_DIR + 'two_cell.sorted.bam.bai'
	message: 'Index sorted bam file {input}'
	params: h_vmem = '8g', bigio = '0',
	        name = 'index_bam'
	log: LOG_DIR
	shell: '{SAMTOOLS}samtools index {input}'

rule rmdup_umi:
	input: bam = UMI_DIR + 'two_cell.sorted.bam',
               index = UMI_DIR + 'two_cell.sorted.bam.bai',
	output: bam = UMI_DIR + 'two_cell.umi.bam',
                bed = UMI_DIR + 'two_cell.umi.diffs.bed',
	message: 'Remove reads with duplicated UMIs for {input.bam}'
	params: h_vmem = '16g', bigio = '0',
	        name = 'rmdup_umi'
	log: LOG_DIR
	shell: '{UMITOOLS}umitools rmdup {input.bam} {output.bam} > {output.bed}'

rule download_exons:
	output: DATA_DIR + '/genome/exons.saf'
	message: 'Create SAF file of human exons.'
	params: h_vmem = '8g', bigio = '0',
	        name = 'download_exons'
	log: LOG_DIR
	shell: 'Rscript download_exons.R > {output}'

rule ercc_tab:
	input: DATA_DIR + '/genome/ERCC92.fa'
	output: DATA_DIR + '/genome/ERCC92.txt'
	message: 'Create tab-sep text file of ERCC sequences.'
	params: h_vmem = '8g', bigio = '0',
	        name = 'ercc_tab'
	log: LOG_DIR
	run:
          out = open(output[0], 'w')
          for seq_record in SeqIO.parse(input[0], 'fasta'):
              out.write('%s\t%s\t1\t%d\t+\n'%(seq_record.id, seq_record.id,
                                              len(seq_record)))
          out.close()

rule combine_features:
	input: exons = DATA_DIR + '/genome/exons.saf',
               ercc = DATA_DIR + '/genome/ERCC92.txt'
	output: DATA_DIR + '/genome/exons_ERCC92.saf'
	message: 'Combine human exons and ERCC sequences.'
	params: h_vmem = '8g', bigio = '0',
	        name = 'combine_features'
	log: LOG_DIR
	shell: 'cat {input.exons} {input.ercc} > {output}'

rule featureCounts:
	input: reads = UMI_DIR + 'two_cell.sorted.bam',
               umi = UMI_DIR + 'two_cell.umi.bam',
               anno = DATA_DIR + '/genome/exons_ERCC92.saf'
	output: counts = UMI_DIR + 'two_cell.counts.txt',
                summary = UMI_DIR + 'two_cell.counts.txt.summary'
	message: 'Counts number of reads per feature for {input.umi}.'
	params: h_vmem = '8g', bigio = '1',
	        name = 'featureCounts'
	log: LOG_DIR
	shell: '{SUBREAD}featureCounts -a {input.anno} -F SAF -o {output.counts} {input.reads} {input.umi}'

subworkflow population:
	snakefile: 'Snakefile-population'

rule combine_counts:
	input: umi = UMI_DIR + 'two_cell.counts.txt',
               pop = population(POP_DIR + 'NA19239_yale.counts.txt')
	output: DATA_DIR + 'count_matrix.txt'
	message: 'Combine counts into one matrix.'
	params: h_vmem = '8g', bigio = '0',
	        name = 'combine_counts'
	log: LOG_DIR
	shell: 'cut -f7 {input.pop} | paste {input.umi} - > {output}'

rule download_ercc_info:
	output: DATA_DIR + 'ercc_info.txt'
	message: 'Download concentration info of ERCC spike-in mix.'
	params: h_vmem = '8g', bigio = '0',
	        name = 'download_ercc_info'
	log: LOG_DIR
	shell: '''wget http://tools.lifetechnologies.com/content/sfs/manuals/cms_095046.txt;
                  mv cms_095046.txt {output}'''
